{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCBHbOcUp51L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install Required Dependencies\n",
        "# This cell installs all necessary libraries for the AI Image Generator\n",
        "\n",
        "!pip install -q diffusers transformers accelerate safetensors\n",
        "!pip install -q torch torchvision\n",
        "!pip install -q Pillow\n",
        "!pip install -q gradio  # Using Gradio instead of Streamlit for Colab compatibility\n",
        "\n",
        "print(\"âœ“ All dependencies installed successfully!\")"
      ],
      "metadata": {
        "id": "AzuPDap2qJkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import Libraries and Check GPU Availability\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from datetime import datetime\n",
        "from PIL import Image\n",
        "import json\n",
        "import re\n",
        "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
        "from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "import gradio as gr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check device availability\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"\\u2713 Using device: {device}\")\n",
        "\n",
        "if device == \"cuda\":\n",
        "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"  âš  Running on CPU - Generation will be slower\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs('/content/outputs', exist_ok=True)\n",
        "print(f\"\\u2713 Output directory created at: /content/outputs\")"
      ],
      "metadata": {
        "id": "OcV3DGp-qd1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load Stable Diffusion Model\n",
        "# Using Stable Diffusion v1.5 for compatibility and speed\n",
        "\n",
        "print(\"Loading Stable Diffusion model...\")\n",
        "print(\"This may take a few minutes on first run...\\n\")\n",
        "\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "\n",
        "try:\n",
        "    # Load pipeline with optimizations\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "        safety_checker=StableDiffusionSafetyChecker.from_pretrained(\n",
        "            \"CompVis/stable-diffusion-safety-checker\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Use efficient scheduler\n",
        "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "    # Move to device\n",
        "    pipe = pipe.to(device)\n",
        "\n",
        "    # Enable memory optimization for CPU\n",
        "    if device == \"cpu\":\n",
        "        pipe.enable_attention_slicing()\n",
        "        print(\"âœ“ Enabled attention slicing for CPU optimization\")\n",
        "    else:\n",
        "        # Enable memory efficient attention for GPU\n",
        "        try:\n",
        "            pipe.enable_xformers_memory_efficient_attention()\n",
        "            print(\"âœ“ Enabled xformers memory efficient attention\")\n",
        "        except:\n",
        "            print(\"âš  xformers not available, using default attention\")\n",
        "\n",
        "    print(f\"\\nâœ“ Model loaded successfully on {device}!\")\n",
        "    print(f\"  Model: {model_id}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error loading model: {str(e)}\")\n",
        "    print(\"\\nTrying alternative loading method...\")\n",
        "    # Fallback to basic loading\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(model_id)\n",
        "    pipe = pipe.to(device)\n",
        "    print(\"âœ“ Model loaded with basic configuration\")"
      ],
      "metadata": {
        "id": "YsU-qQmbqz0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Prompt Engineering and Content Filtering\n",
        "\n",
        "NSFW_KEYWORDS = ['nude', 'naked', 'nsfw', 'xxx', 'porn', 'sexual', 'explicit', 'violent', 'gore', 'blood', 'weapon']\n",
        "\n",
        "def check_prompt_safety(prompt):\n",
        "    prompt_lower = prompt.lower()\n",
        "    for keyword in NSFW_KEYWORDS:\n",
        "        if keyword in prompt_lower:\n",
        "            return False, f\"âŒ Inappropriate content: '{keyword}'\"\n",
        "    return True, \"âœ“ Safe\"\n",
        "\n",
        "def enhance_prompt(prompt, style=\"photorealistic\"):\n",
        "    styles = {\n",
        "        \"photorealistic\": \"highly detailed, 4K, professional photography, sharp focus, realistic lighting\",\n",
        "        \"artistic\": \"beautiful, artistic, detailed painting, masterpiece, trending on artstation\",\n",
        "        \"cartoon\": \"cartoon style, colorful, vibrant, digital art, cute, animated\",\n",
        "        \"cinematic\": \"cinematic lighting, dramatic, epic scene, movie poster style\",\n",
        "        \"fantasy\": \"fantasy art, magical, ethereal, detailed, mystical atmosphere\"\n",
        "    }\n",
        "    return f\"{prompt}, {styles.get(style, styles['photorealistic'])}\"\n",
        "\n",
        "def add_watermark(img):\n",
        "    from PIL import ImageDraw, ImageFont\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    text = \"AI Generated - Talrn Assessment\"\n",
        "    font = ImageFont.load_default()\n",
        "    w, h = img.size\n",
        "    draw.text((w-180, h-20), text, fill=(255,255,255), font=font)\n",
        "    draw.text((w-181, h-21), text, fill=(0,0,0), font=font)  # shadow\n",
        "    return img\n",
        "\n",
        "print(\"âœ“ Safety and prompt engineering ready\")\n"
      ],
      "metadata": {
        "id": "ULE6rpWsrCzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Image Generation Function with Storage\n",
        "\n",
        "def generate_images(prompt, num_images=1, style=\"photorealistic\", negative_prompt=\"\", steps=20):\n",
        "    \"\"\"\n",
        "    Generate images from text prompt with safety checks and metadata storage\n",
        "    \"\"\"\n",
        "    # Safety check\n",
        "    is_safe, safety_msg = check_prompt_safety(prompt)\n",
        "    if not is_safe:\n",
        "        return None, safety_msg\n",
        "\n",
        "    # Enhance prompt\n",
        "    enhanced_prompt = enhance_prompt(prompt, style)\n",
        "\n",
        "    # Default negative prompt\n",
        "    if not negative_prompt:\n",
        "        negative_prompt = \"blurry, bad quality, distorted, ugly, low resolution\"\n",
        "\n",
        "    print(f\"\\nâœ“ Generating {num_images} image(s)...\")\n",
        "    print(f\"  Original prompt: {prompt}\")\n",
        "    print(f\"  Enhanced prompt: {enhanced_prompt}\")\n",
        "    print(f\"  Style: {style}\")\n",
        "    print(f\"  Inference steps: {steps}\")\n",
        "\n",
        "    generated_images = []\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    try:\n",
        "        for i in range(num_images):\n",
        "            print(f\"\\n  Generating image {i+1}/{num_images}...\")\n",
        "\n",
        "            # Generate image\n",
        "            with torch.no_grad():\n",
        "                image = pipe(\n",
        "                    enhanced_prompt,\n",
        "                    negative_prompt=negative_prompt,\n",
        "                    num_inference_steps=steps,\n",
        "                    guidance_scale=7.5,\n",
        "                    height=512,\n",
        "                    width=512\n",
        "                ).images[0]\n",
        "\n",
        "            # Add watermark\n",
        "            image = add_watermark(image)\n",
        "\n",
        "            # Save image with metadata\n",
        "            filename = f\"image_{timestamp}_{i+1}.png\"\n",
        "            filepath = os.path.join('/content/outputs', filename)\n",
        "            image.save(filepath)\n",
        "\n",
        "            # Save metadata\n",
        "            metadata = {\n",
        "                \"filename\": filename,\n",
        "                \"prompt\": prompt,\n",
        "                \"enhanced_prompt\": enhanced_prompt,\n",
        "                \"style\": style,\n",
        "                \"negative_prompt\": negative_prompt,\n",
        "                \"steps\": steps,\n",
        "                \"timestamp\": timestamp,\n",
        "                \"device\": device\n",
        "            }\n",
        "\n",
        "            metadata_file = filepath.replace('.png', '_metadata.json')\n",
        "            with open(metadata_file, 'w') as f:\n",
        "                json.dump(metadata, f, indent=2)\n",
        "\n",
        "            generated_images.append(image)\n",
        "            print(f\"  âœ“ Saved: {filepath}\")\n",
        "\n",
        "        print(f\"\\nâœ“ Successfully generated {num_images} image(s)!\")\n",
        "        return generated_images, f\"âœ“ Successfully generated {num_images} image(s)\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ Error: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        return None, error_msg\n",
        "\n",
        "print(\"âœ“ Image generation function ready\")"
      ],
      "metadata": {
        "id": "ovbgDz2ZryI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Build Gradio Web Interface\n",
        "\n",
        "def gradio_generate(prompt, num_images, style, negative_prompt, steps):\n",
        "    \"\"\"\n",
        "    Wrapper function for Gradio interface\n",
        "    \"\"\"\n",
        "    images, message = generate_images(prompt, int(num_images), style, negative_prompt, int(steps))\n",
        "    if images is None:\n",
        "        return [], message\n",
        "    return images, message\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks(title=\"AI Image Generator - Talrn Assessment\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ğŸ¨ AI-Powered Image Generator\n",
        "    ### Talrn ML Internship Task - Text-to-Image Generation\n",
        "\n",
        "    Generate high-quality images from text descriptions using Stable Diffusion.\n",
        "\n",
        "    **Features:**\n",
        "    - Multiple style presets (Photorealistic, Artistic, Cartoon, Cinematic, Fantasy)\n",
        "    - Content filtering for safe generation\n",
        "    - Automatic watermarking\n",
        "    - Metadata storage with each image\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            prompt_input = gr.Textbox(\n",
        "                label=\"ğŸ“ Prompt\",\n",
        "                placeholder=\"Describe the image you want to generate...\",\n",
        "                lines=3\n",
        "            )\n",
        "\n",
        "            style_dropdown = gr.Dropdown(\n",
        "                choices=[\"photorealistic\", \"artistic\", \"cartoon\", \"cinematic\", \"fantasy\"],\n",
        "                value=\"photorealistic\",\n",
        "                label=\"ğŸ¨ Style\"\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                num_images_slider = gr.Slider(\n",
        "                    minimum=1,\n",
        "                    maximum=4,\n",
        "                    value=1,\n",
        "                    step=1,\n",
        "                    label=\"ğŸ”¢ Number of Images\"\n",
        "                )\n",
        "\n",
        "                steps_slider = gr.Slider(\n",
        "                    minimum=10,\n",
        "                    maximum=50,\n",
        "                    value=20,\n",
        "                    step=5,\n",
        "                    label=\"ğŸ”„ Inference Steps (Higher = Better Quality)\"\n",
        "                )\n",
        "\n",
        "            negative_prompt_input = gr.Textbox(\n",
        "                label=\"â›” Negative Prompt (Optional)\",\n",
        "                placeholder=\"What to avoid in the image...\",\n",
        "                lines=2,\n",
        "                value=\"blurry, bad quality, distorted, ugly, low resolution\"\n",
        "            )\n",
        "\n",
        "            generate_btn = gr.Button(\"âœ¨ Generate Images\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_gallery = gr.Gallery(\n",
        "                label=\"ğŸ–¼ï¸ Generated Images\",\n",
        "                columns=2,\n",
        "                height=\"auto\"\n",
        "            )\n",
        "            status_output = gr.Textbox(label=\"ğŸ“Š Status\", interactive=False)\n",
        "\n",
        "    # Examples\n",
        "    gr.Markdown(\"### ğŸ’¡ Example Prompts\")\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"A futuristic city at sunset\", 1, \"cinematic\", \"\", 20],\n",
        "            [\"Portrait of a robot in Van Gogh style\", 1, \"artistic\", \"\", 25],\n",
        "            [\"A cute cat wearing a wizard hat\", 1, \"cartoon\", \"\", 20],\n",
        "            [\"A mystical forest with glowing mushrooms\", 1, \"fantasy\", \"\", 25],\n",
        "            [\"Professional photo of a mountain landscape\", 1, \"photorealistic\", \"\", 30]\n",
        "        ],\n",
        "        inputs=[prompt_input, num_images_slider, style_dropdown, negative_prompt_input, steps_slider]\n",
        "    )\n",
        "\n",
        "    # Connect button to function\n",
        "    generate_btn.click(\n",
        "        fn=gradio_generate,\n",
        "        inputs=[prompt_input, num_images_slider, style_dropdown, negative_prompt_input, steps_slider],\n",
        "        outputs=[output_gallery, status_output]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ---\n",
        "    **â„¹ï¸ Note:** Images are automatically saved to `/content/outputs/` with metadata.\n",
        "\n",
        "    **âš ï¸ Responsible Use Guidelines:**\n",
        "    - Do not generate inappropriate, violent, or harmful content\n",
        "    - All images are watermarked to indicate AI generation\n",
        "    - Content filtering is active to prevent misuse\n",
        "    \"\"\")\n",
        "\n",
        "print(\"âœ“ Gradio interface created!\")\n",
        "print(\"\\nLaunching web interface...\\n\")"
      ],
      "metadata": {
        "id": "ku-tiMxSsIjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Launch the Web Interface\n",
        "\n",
        "# Launch with share=True to get a public URL\n",
        "demo.launch(share=True, debug=False)"
      ],
      "metadata": {
        "id": "XhpzsTevsVv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ARMooPgLslI1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cfhIt_PjsonU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# ğŸ“š PROJECT DOCUMENTATION\n",
        "\n",
        "## AI-Powered Image Generator - Talrn ML Internship Assessment\n",
        "\n",
        "### ğŸ¯ Project Overview\n",
        "This project implements a complete **Text-to-Image Generation System** using Stable Diffusion v1.5, featuring a modern Gradio web interface, content filtering, prompt engineering, and comprehensive metadata storage.\n",
        "\n",
        "### âœ¨ Key Features\n",
        "- **Multi-Style Generation**: 5 style presets (Photorealistic, Artistic, Cartoon, Cinematic, Fantasy)\n",
        "- **Safety First**: Automatic content filtering for inappropriate prompts\n",
        "- **Smart Prompts**: Built-in prompt engineering to enhance quality\n",
        "- **Metadata Storage**: Every image saved with full generation parameters\n",
        "- **Watermarking**: All images marked as AI-generated\n",
        "- **GPU/CPU Support**: Automatic device detection with CPU fallback\n",
        "- **Web Interface**: User-friendly Gradio UI with live preview\n",
        "\n",
        "### ğŸ› ï¸ Technology Stack\n",
        "- **Model**: Stable Diffusion v1.5 (runwayml/stable-diffusion-v1-5)\n",
        "- **Framework**: PyTorch\n",
        "- **UI**: Gradio\n",
        "- **Libraries**: Diffusers, Transformers, Accelerate, PIL\n",
        "\n",
        "### ğŸ’» Hardware Requirements\n",
        "- **GPU**: Recommended (15GB+ VRAM for optimal performance)\n",
        "- **CPU**: Supported with reduced speed (16GB+ RAM recommended)\n",
        "- **Storage**: ~5GB for model weights\n",
        "\n",
        "### ğŸš€ Quick Start (This Colab)\n",
        "1. Run all cells in order (Ctrl+F9)\n",
        "2. Wait for model download (~2-3 minutes)\n",
        "3. Access the Gradio interface (URL appears after launch)\n",
        "4. Enter your prompt and generate!\n",
        "\n",
        "### ğŸ“ Project Structure\n",
        "```\n",
        "/content/outputs/          # Generated images & metadata\n",
        "Step 1: Dependencies       # Install required packages\n",
        "Step 2: Imports & Setup    # Initialize environment\n",
        "Step 3: Model Loading      # Load Stable Diffusion\n",
        "Step 4: Prompt Engineering # Safety & enhancement\n",
        "Step 5: Generation Logic   # Core image generation\n",
        "Step 6: Gradio Interface   # Web UI\n",
        "Step 7: Launch            # Start server\n",
        "```\n",
        "\n",
        "### ğŸ’¡ Prompt Engineering Tips\n",
        "- **Be Specific**: \"A red sports car at sunset\" > \"a car\"\n",
        "- **Add Quality Terms**: The system auto-adds \"4K, detailed, professional\"\n",
        "- **Use Negative Prompts**: Avoid unwanted elements\n",
        "- **Experiment with Styles**: Each style adds unique characteristics\n",
        "\n",
        "### ğŸ”’ Responsible AI Use\n",
        "âš ï¸ **Content Policy**:\n",
        "- No violent, explicit, or harmful content\n",
        "- All images are watermarked\n",
        "- Content filtering is always active\n",
        "- Respect intellectual property\n",
        "\n",
        "### ğŸ“Š Performance Notes\n",
        "- **GPU (T4)**: ~15-20 seconds per image\n",
        "- **CPU**: ~2-5 minutes per image\n",
        "- **Steps**: 20 (balanced), 30+ (higher quality, slower)\n",
        "\n",
        "### ğŸ”§ Customization Options\n",
        "You can modify:\n",
        "- Image resolution (currently 512x512)\n",
        "- Inference steps (10-50)\n",
        "- Guidance scale (default 7.5)\n",
        "- Number of images per batch (1-4)\n",
        "\n",
        "### ğŸ’¾ Output Files\n",
        "Each generation creates:\n",
        "```\n",
        "image_YYYYMMDD_HHMMSS_1.png     # The generated image\n",
        "image_YYYYMMDD_HHMMSS_1_metadata.json  # Full parameters\n",
        "```\n",
        "\n",
        "### â— Limitations\n",
        "- Generation time varies with hardware\n",
        "- CPU mode is significantly slower\n",
        "- Limited to 512x512 resolution (optimized for speed)\n",
        "- Public Gradio links expire after 72 hours\n",
        "\n",
        "### ğŸš€ Future Enhancements\n",
        "- Higher resolution support (768x768, 1024x1024)\n",
        "- Custom model fine-tuning\n",
        "- Img2img transformation\n",
        "- Inpainting capabilities\n",
        "- Style transfer features\n",
        "- Batch processing\n",
        "\n",
        "### ğŸ“ Example Prompts\n",
        "1. **Landscape**: \"A serene mountain lake at golden hour, mist rising, professional photography\"\n",
        "2. **Portrait**: \"Portrait of a cyberpunk character, neon lights, highly detailed, digital art\"\n",
        "3. **Abstract**: \"Colorful abstract painting, flowing shapes, vibrant colors, modern art\"\n",
        "4. **Fantasy**: \"A magical forest with bioluminescent plants, ethereal atmosphere, fantasy art\"\n",
        "\n",
        "### ğŸ‘¤ Author\n",
        "Submitted for Talrn ML Internship Assessment\n",
        "\n",
        "### ğŸ’¬ Support\n",
        "For questions about this implementation, refer to the inline code comments or documentation.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "eKkyJVrlsrF3"
      }
    }
  ]
}